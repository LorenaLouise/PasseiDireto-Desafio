{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38164bitd5bc87fb421e45628329ba83dfedeba2",
   "display_name": "Python 3.8.1 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Desafio PasseiDireto - Parte 1\n",
    "Na primeira parte do desafio, criei a solução em um notebook para melhor explicação das etapas.\n",
    "É importante ler o Readme primeiro, pois no documento explico minha forma de pensar na arquitetura do CASE."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Importação de bibliotecas e conexão do Banco de dados."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd;\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conexao import alchemy_connection\n",
    "engine = alchemy_connection('CASE_PD')"
   ]
  },
  {
   "source": [
    "## Leitura dos DataSets\n",
    "Leitura dos dataSets para vários DataFrames. Json -> DataFrame"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leitura Full - Desafio\n",
    "path_BASEA = \"Datasets - Teste Data Engineer - Passei Direto\\BASE A\"\n",
    "dfCourses = pd.read_json(f'{path_BASEA}\\courses.json')\n",
    "dfSessions = pd.read_json(f'{path_BASEA}\\sessions.json')\n",
    "dfStudents = pd.read_json(f'{path_BASEA}\\students.json')\n",
    "dfSubjects = pd.read_json(f'{path_BASEA}\\subjects.json')\n",
    "dfSubscriptions = pd.read_json(f'{path_BASEA}\\subscriptions.json')\n",
    "dfUniversities = pd.read_json('Datasets - Teste Data Engineer - Passei Direto\\\\BASE A\\\\universities.json')\n",
    "dfStudentSubject = pd.read_json('Datasets - Teste Data Engineer - Passei Direto\\\\BASE A\\\\student_follow_subject.json')"
   ]
  },
  {
   "source": [
    "### Leituras de Modo Incremental\n",
    "Levando em conta a arquitetura do README. Aqui estou fazendo uma leitura incremental M-1.Em um ambiente S3 ou local , como o exemplo atual , eu separaria em \"pasta\" os datasets de cada mês. O Código está comentado para não impactar no restante."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leitura Incremental.\n",
    "\n",
    "# today = datetime.date.today()\n",
    "# first = today.replace(day=1)\n",
    "# lastMonth = first - datetime.timedelta(days=1)\n",
    "# lastMonthT=lastMonth.strftime(\"%Y%m\")\n",
    "# path = \"Datasets - Teste Data Engineer - Passei Direto\\BASE INCR\\{lastMonthT}\"\n",
    "# dfCourses = pd.read_json(f'{path}\\courses.json')\n",
    "# dfSessions = pd.read_json(f'{path}/sessions.json')\n",
    "# dfStudents = pd.read_json(f'{path}/students.json')\n",
    "# dfSubjects = pd.read_json(f'{path}/subjects.json')\n",
    "# dfSubscriptions = pd.read_json(f'{path}/subscriptions.json')\n",
    "# dfUniversities = pd.read_json(f'{path}/universities.json')\n",
    "# dfStudentSubject = pd.read_json(f'{path}/student_follow_subject.json')\n"
   ]
  },
  {
   "source": [
    "## Tratamento dos dados\n",
    "1. Primeiro foi feito a modelagem dimensional e logo após inicia-se o tratamento dos dados.\n",
    "2. Foi encontrado dados de usuários duplicados no DataSet, pois os usuários haviam feito 2 pagamentos no mesmo mês de novembro.O objetivo foi apenas extrair o tipo de plano de cada usuário, então foi retirado a coluna: PaymentDate e as duplicatas.\n",
    "3. Em seguida, foi criado tabelas Stages para inserir todos os dados Temporariamente.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subscription possui valores de Estudantes duplicados.Retirei o PaymentDate pois não será feito anáise em cima desse campo.\n",
    "dfSubscriptions.drop('PaymentDate',axis='columns',inplace=True)\n",
    "dfSubscriptions.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStudentSubject.to_sql(\n",
    "    name='STG_STUDENT_SUBJECT',\n",
    "    con=engine,\n",
    "    schema='CASE_01_STG',\n",
    "    if_exists='replace',\n",
    "    index=False\n",
    ")\n",
    "dfCourses.to_sql(\n",
    "    name='STG_CURSO',\n",
    "    con=engine,\n",
    "    schema='CASE_01_STG',\n",
    "    if_exists='replace',\n",
    "    index=False\n",
    ")\n",
    "dfSessions.to_sql(\n",
    "    name='STG_SESSION',\n",
    "    con=engine,\n",
    "    schema='CASE_01_STG',\n",
    "    if_exists='replace',\n",
    "    index=False\n",
    ")\n",
    "dfStudents.to_sql(\n",
    "    name='STG_STUDENT',\n",
    "    con=engine,\n",
    "    schema='CASE_01_STG',\n",
    "    if_exists='replace',\n",
    "    index=False\n",
    ")\n",
    "dfSubjects.to_sql(\n",
    "    name='STG_SUBJECT',\n",
    "    con=engine,\n",
    "    schema='CASE_01_STG',\n",
    "    if_exists='replace',\n",
    "    index=False\n",
    ")\n",
    "dfSubscriptions.to_sql(\n",
    "    name='STG_SUBSCRIPTION',\n",
    "    con=engine,\n",
    "    schema='CASE_01_STG',\n",
    "    if_exists='replace',\n",
    "    index=False\n",
    ")\n",
    "dfUniversities.to_sql(\n",
    "    name='STG_UNIVERSITY',\n",
    "    con=engine,\n",
    "    schema='CASE_01_STG',\n",
    "    if_exists='replace',\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "source": [
    "## Criação e Tratamento das Dimensões\n",
    "1. Primeiro extraimos todos os dados da Stage para vários DataFrame."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStgCourses = pd.read_sql_table('STG_CURSO',engine,schema='CASE_01_STG')\n",
    "dfStgSession = pd.read_sql_table('STG_SESSION',engine,schema='CASE_01_STG')\n",
    "dfStgStudent = pd.read_sql_table('STG_STUDENT',engine,schema='CASE_01_STG')\n",
    "dfStgSubject = pd.read_sql_table('STG_SUBJECT',engine,schema='CASE_01_STG')\n",
    "dfStgSubscription = pd.read_sql_table('STG_SUBSCRIPTION',engine,schema='CASE_01_STG')\n",
    "dfStgUniversity = pd.read_sql_table('STG_UNIVERSITY',engine,schema='CASE_01_STG')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verifica se Existe valores duplicados nas Stages\n",
    "#dfDuplicates=dfUniversities.duplicated(subset=None, keep='first')\n",
    "#dfSessions.isnull().sum()"
   ]
  },
  {
   "source": [
    "2. Seguindo o modelo Star Schema, vamos criar duas dimensões para o nosso case : Dimensão Student e Dimensão Disciplina. A seguir, temos uma junção de vários dados relevantes na dimensão Student: Id,Plan Type,Registered Date, State,City, University, Course, Signup Source, Student Client.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfStgStudent = pd.merge(dfStgStudent,dfStgUniversity,how='left', left_on='UniversityId', right_on='Id').rename(columns={'Id_x':'IdStudent','Name':'UniversityName'})\n",
    "dfStgStudent.drop(['Id_y','UniversityId'],axis=1,inplace=True)\n",
    "dfStgStudent = pd.merge(dfStgStudent,dfStgCourses,how='left', left_on='CourseId', right_on='Id').rename(columns={'Name':'CourseName'})\n",
    "dfStgStudent.drop(['CourseId','Id'],axis=1,inplace=True)\n",
    "dfStgStudent = pd.merge(dfStgStudent,dfStgSubscription,how='left',left_on='IdStudent',right_on='StudentId')\n",
    "dfStgStudent.drop(['StudentId'],axis=1,inplace=True)"
   ]
  },
  {
   "source": [
    "3.Foi Identificado que algumas colunas estão com o valor None, sem informação. Portanto foi feito a seguinte tratativa para cada linha: Caso o estado ou cidade estivesse preenchido iriamos repetir o valor no campo faltante."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tratando dados de Estado e Cidade\n",
    "for i,n in dfStgStudent.iterrows():\n",
    "    if n[\"City\"] is None and n[\"State\"] is not None:\n",
    "        dfStgStudent.loc[i,\"City\"] = n['State']\n",
    "    elif n[\"State\"] is None and n[\"City\"] is not None:\n",
    "        dfStgStudent.loc[i,\"State\"] = n['City']"
   ]
  },
  {
   "source": [
    "4. Ao fazer a junção dos dados, identificamos que nem todos os usuários possuem plano. Portanto seguindo as boas práticas, preenchemos com o valor \"Sem plano\" para os usuários que não possuem o plano premium.\n",
    "5. Logo em seguida, foi preenchido com o valor \"Não informado\" aqueles campos que o usuário não preencheu ou não contém dados no sistema.\n",
    "6. Foi identificado que uma amostra de dados possuem Apóstrafo , o que está dificultando a inserção no banco de dados.O correto seria retirar todos os acentos,caracteres especiais para inserir no banco. Foi feito alguns exemplos desses tratamentos."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tratando dados Nulos e com Apóstrofos\n",
    "dfStgStudent['PlanType'].fillna('Sem Plano',inplace=True)\n",
    "dfStgStudent.fillna('Nao Informado',inplace=True)\n",
    "\n",
    "dfStgStudent['City']=dfStgStudent['City'].str.replace(\"'\",\"\")\n",
    "dfStgSubject['Name']=dfStgSubject['Name'].str.replace(\"'\",\"\")"
   ]
  },
  {
   "source": [
    "7. Neste tópico, foi criado funções para execução das queries das dimensões e fatos. Temos um exemplo de Insert/Update das Dimensões. Caso haja algum dado novo, iremos inserir. Se não, irá atualizar os dados.\n",
    "8. Logo em seguida , chamo as funções para criar o nosso modelo Star Schema."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criação do cursor\n",
    "connection =  engine.raw_connection()\n",
    "cursorteste = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def iu_subject(dataframe):\n",
    "    for n,i in dataframe.iterrows():\n",
    "        query = f\"\"\"\n",
    "        IF EXISTS(SELECT ID FROM [CASE_PD].[CASE_01_DW].[DIM_SUBJECT] WHERE ID = {i[0]}) \n",
    "            BEGIN \n",
    "                UPDATE [CASE_PD].[CASE_01_DW].[DIM_SUBJECT] set Name=\\'{i[1]}\\' where ID={i[0]} \n",
    "            END \n",
    "\n",
    "        ELSE \n",
    "            BEGIN \n",
    "                insert into [CASE_PD].[CASE_01_DW].[DIM_SUBJECT] values({i[0]},\\'{i[1]}\\') \n",
    "            END\n",
    "        \"\"\"\n",
    "        cursorteste.execute(query)\n",
    "    cursorteste.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iu_dimStudent(dataframe):\n",
    "    for i,n in dataframe.iterrows():\n",
    "        query = f\"\"\"\n",
    "                      IF EXISTS(SELECT ID FROM [CASE_PD].[CASE_01_DW].[DIM_STUDENT] WHERE ID =\\'{n['IdStudent']}\\') \n",
    "                        BEGIN \n",
    "                        UPDATE [CASE_PD].[CASE_01_DW].[DIM_STUDENT] set PLAN_TYPE=\\'{n['PlanType']}\\',STATE=\\'{n['State']}\\',CITY=\\'{n['City']}\\', UNIVERSITY=\\'{n['UniversityName']}\\',COURSE=\\'{n['CourseName']}\\' where ID=\\'{n['IdStudent']}\\'\n",
    "                        END\n",
    "                    ELSE \n",
    "                        BEGIN \n",
    "                            insert into [CASE_PD].[CASE_01_DW].[DIM_STUDENT] (ID,PLAN_TYPE,REGISTERED_DATE,STATE,CITY,UNIVERSITY,COURSE,SIGNUP_SOURCE,STUDENT_CLIENT) values(\\'{n['IdStudent']}\\',\\'{n['PlanType']}\\',\\'{n['RegisteredDate']}\\',\\'{n['State']}\\',\\'{n['City']}\\',\\'{n['UniversityName']}\\',\\'{n['CourseName']}\\',\\'{n['SignupSource']}\\',\\'{n['StudentClient']}\\') \n",
    "                        END\n",
    "        \"\"\"\n",
    "        cursorteste.execute(query)\n",
    "    cursorteste.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carregar_tabela_fato_session():\n",
    "    insert=\"\"\"INSERT INTO [CASE_01_DW].[FATO_SESSION] \"\"\"\n",
    "    select=\"\"\"SELECT IIF(Student.SK_STUDENT is null, -7,Student.SK_STUDENT)\n",
    "                    ,[SessionStartTime]\n",
    "                    ,[SessionStartTime]\n",
    "                    ,[StudentClient]\n",
    "                FROM [CASE_PD].[CASE_01_STG].[STG_SESSION] Session\n",
    "                LEFT JOIN [CASE_PD].[CASE_01_DW].[DIM_STUDENT] Student\n",
    "                ON Session.StudentId = Student.Id\"\"\"\n",
    "\n",
    "    query = insert + select\n",
    "    cursorteste.execute(query)\n",
    "    cursorteste.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carregar_tabela_fato_follow():\n",
    "    insert=\"\"\"INSERT INTO [CASE_01_DW].[FATO_FOLLOW_SUBJECT] \"\"\"\n",
    "    select=\"\"\"SELECT IIF(Student.SK_STUDENT is null, -7,Student.SK_STUDENT)\n",
    "                    ,IIF(SUBJECT.SK_SUBJECT is null, -7,SUBJECT.SK_SUBJECT)\n",
    "                    ,[FollowDate]\n",
    "                FROM [CASE_PD].[CASE_01_STG].[STG_STUDENT_SUBJECT] STD_SUBJCT\n",
    "                LEFT JOIN [CASE_PD].[CASE_01_DW].[DIM_STUDENT] STUDENT\n",
    "                ON STD_SUBJCT.StudentId = STUDENT.Id\n",
    "                LEFT JOIN [CASE_PD].[CASE_01_DW].[DIM_SUBJECT] SUBJECT\n",
    "                ON STD_SUBJCT.SubjectId = SUBJECT.Id\"\"\"\n",
    "\n",
    "    query = insert + select\n",
    "    cursorteste.execute(query)\n",
    "    cursorteste.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "iu_dimStudent(dfStgStudent)\n",
    "iu_subject(dfStgSubject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "carregar_tabela_fato_session()\n",
    "carregar_tabela_fato_follow()"
   ]
  }
 ]
}